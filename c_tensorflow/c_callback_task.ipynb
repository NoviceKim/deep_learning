{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fadb4a8-edc2-410f-b814-686c3293d23d",
   "metadata": {},
   "source": [
    "### Callback API Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3f05b56-b4d3-4bfc-8a64-1744544aa9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset shape: (60000, 28, 28) (60000,)\n",
      "test dataset shape: (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print(\"train dataset shape:\", train_images.shape, train_labels.shape)\n",
    "print(\"test dataset shape:\", test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "478afe34-c1dc-4843-8936-0cfd08536ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# train 이미지 중 하나 골라서 형태 시각화하고, 어느 분류에 속하는 지 확인(레이블 인코딩 된 결과)\n",
    "plt.imshow(train_images[2500], cmap='gray')\n",
    "plt.title(train_labels[2500])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e37d066b-d8a0-4283-a12b-9ac5c0ae701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer, Input, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "INPUT_SIZE = 28\n",
    "\n",
    "# 모델 생성 함수 선언\n",
    "def create_model():\n",
    "    input_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE))\n",
    "\n",
    "    x = Flatten()(input_tensor)\n",
    "\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "\n",
    "    output = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "692030fe-d38a-43cf-b15f-0131df9f6d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# images MinMaxScaling 함수 선언\n",
    "def get_preprocessed_data(images, targets):\n",
    "    images = np.array(images / 255.0, dtype=np.float32)\n",
    "    targets = np.array(targets, dtype=np.float32)\n",
    "\n",
    "    return images, targets\n",
    "\n",
    "# targets 원핫 인코딩 함수 선언 (+ images MinMaxScaling)\n",
    "def get_preprocessed_ohe(images, targets):\n",
    "    images, targets = get_preprocessed_data(images, targets)\n",
    "    oh_targets = to_categorical(targets)\n",
    "\n",
    "    return images, oh_targets\n",
    "\n",
    "# train 데이터에서 validation 데이터 분리하는 함수 선언 (+ images MinMaxScaling, targets 원핫 인코딩)\n",
    "def get_train_valid_test(train_images, train_targets, test_images, test_targets, validation_size=0.2, random_state=124):\n",
    "    train_images, train_oh_targets = get_preprocessed_ohe(train_images, train_targets)\n",
    "    test_images, test_oh_targets = get_preprocessed_ohe(test_images, test_targets)\n",
    "\n",
    "    train_images, validation_images, train_oh_targets, validation_oh_targets = \\\n",
    "    train_test_split(train_images, train_oh_targets, stratify=train_oh_targets, test_size=validation_size, random_state=random_state)\n",
    "\n",
    "    return (train_images, train_oh_targets), (validation_images, validation_oh_targets), (test_images, test_oh_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7376199-a385-4824-9d39-d24b80d93ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28) (48000, 10)\n",
      "(12000, 28, 28) (12000, 10)\n",
      "(10000, 28, 28) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# 위에서 선언한 함수로 스케일링, 원핫 인코딩, validation 데이터 분리\n",
    "(train_images, train_oh_labels), (validation_images, validation_oh_labels), (test_images, test_oh_labels) = \\\n",
    "                                            get_train_valid_test(train_images, train_labels, test_images, test_labels)\n",
    "\n",
    "# train, validation, test 데이터 shape 출력\n",
    "print(train_images.shape, train_oh_labels.shape)\n",
    "print(validation_images.shape, validation_oh_labels.shape)\n",
    "print(test_images.shape, test_oh_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6b0c63-2b69-46a5-84a6-6c3f12aa0f8c",
   "metadata": {},
   "source": [
    "#### ModelCheckpoint\n",
    "- save_best_only를 True로 설정해서 좋은 성능을 보인 일부 모델만 저장\n",
    "- 모니터링 기준은 validation 데이터 정확도 최대치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6fb3a45-82ae-4c43-8270-55c74ccf6cc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - acc: 0.8234 - loss: 0.6200 - val_acc: 0.9403 - val_loss: 0.1989\n",
      "Epoch 2/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9514 - loss: 0.1642 - val_acc: 0.9573 - val_loss: 0.1342\n",
      "Epoch 3/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9675 - loss: 0.1102 - val_acc: 0.9649 - val_loss: 0.1139\n",
      "Epoch 4/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9748 - loss: 0.0871 - val_acc: 0.9643 - val_loss: 0.1112\n",
      "Epoch 5/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9806 - loss: 0.0657 - val_acc: 0.9651 - val_loss: 0.1083\n",
      "Epoch 6/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9842 - loss: 0.0529 - val_acc: 0.9682 - val_loss: 0.0981\n",
      "Epoch 7/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9852 - loss: 0.0475 - val_acc: 0.9703 - val_loss: 0.0939\n",
      "Epoch 8/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9881 - loss: 0.0378 - val_acc: 0.9732 - val_loss: 0.0863\n",
      "Epoch 9/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9908 - loss: 0.0296 - val_acc: 0.9746 - val_loss: 0.0884\n",
      "Epoch 10/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9923 - loss: 0.0265 - val_acc: 0.9732 - val_loss: 0.0914\n",
      "Epoch 11/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9942 - loss: 0.0196 - val_acc: 0.9742 - val_loss: 0.0938\n",
      "Epoch 12/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9930 - loss: 0.0225 - val_acc: 0.9741 - val_loss: 0.0969\n",
      "Epoch 13/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9946 - loss: 0.0168 - val_acc: 0.9727 - val_loss: 0.1028\n",
      "Epoch 14/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9951 - loss: 0.0147 - val_acc: 0.9752 - val_loss: 0.1028\n",
      "Epoch 15/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9950 - loss: 0.0154 - val_acc: 0.9747 - val_loss: 0.1072\n",
      "Epoch 16/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9964 - loss: 0.0111 - val_acc: 0.9725 - val_loss: 0.1034\n",
      "Epoch 17/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9970 - loss: 0.0101 - val_acc: 0.9760 - val_loss: 0.1062\n",
      "Epoch 18/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9951 - loss: 0.0151 - val_acc: 0.9758 - val_loss: 0.1120\n",
      "Epoch 19/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9970 - loss: 0.0099 - val_acc: 0.9709 - val_loss: 0.1456\n",
      "Epoch 20/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9961 - loss: 0.0106 - val_acc: 0.9741 - val_loss: 0.1305\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# 모델 컴파일링\n",
    "model = create_model()\n",
    "model.compile(optimizer=Adam(0.001), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "# save_weights_only=False: 가중치가 아닌 모델을 저장 (확장자 .model.keras)\n",
    "mcp_cb = ModelCheckpoint(\n",
    "    filepath=\"./callback_files/model.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.model.keras\",\n",
    "    monitor='val_acc',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "# 모델 훈련과 동시에 train, validation 데이터에 대한 정확도와 loss 이력 저장\n",
    "history = model.fit(x=train_images, \n",
    "                    y=train_oh_labels, \n",
    "                    batch_size=64, \n",
    "                    epochs=20, \n",
    "                    validation_data=(validation_images, validation_oh_labels), callbacks=[mcp_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c28555-aff8-4490-84f9-7e101a2210fc",
   "metadata": {},
   "source": [
    "#### 중간 분석\n",
    "- save_best_only를 True로 설정함에 따라, val_acc의 최대치가 갱신된 시점에만 모델 파일을 내보낸 것을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a45adb51-708c-43b2-912d-7bc7766870d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - acc: 0.9693 - loss: 0.1498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12846389412879944, 0.9742000102996826]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 현재 모델 성능 검증\n",
    "model.evaluate(test_images, test_oh_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "042413d2-0af4-45b4-b463-e04cf4e9665f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - acc: 0.9703 - loss: 0.1344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1134599968791008, 0.9751999974250793]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 가장 val_acc를 보인 모델을 불러와서 위 모델과의 검증 결과 비교\n",
    "model = load_model('./callback_files/model.017-0.1062-0.9964.model.keras')\n",
    "model.evaluate(test_images, test_oh_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df5c4d0-d89a-48af-8e77-69211ff05faa",
   "metadata": {},
   "source": [
    "#### 모델 분석\n",
    "- validation 데이터에 대한 정확도가 가장 높았던 17번째 epoch의 모델을 불러온 결과,  \n",
    "  epoch 20회를 모두 채운 모델보다 우수한 성능을 보이는 것을 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a925ee-ec08-4142-953a-332d8162ee4f",
   "metadata": {},
   "source": [
    "#### ReduceLROnPlateau\n",
    "- patience를 3으로 설정함에 따라 epoch 3회 동안 성능이 개선되지 않으면  \n",
    "  Learning Rate를 알아서 1/10으로 낮추도록 설정\n",
    "- 평가 기준은 위와 마찬가지로 val_acc의 최대치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dd5ba40-076c-4c87-b74e-c5d5949ca82f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - acc: 0.8283 - loss: 0.6008 - val_acc: 0.9507 - val_loss: 0.1701 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9541 - loss: 0.1533 - val_acc: 0.9627 - val_loss: 0.1273 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9667 - loss: 0.1089 - val_acc: 0.9638 - val_loss: 0.1176 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9732 - loss: 0.0859 - val_acc: 0.9684 - val_loss: 0.1029 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9794 - loss: 0.0673 - val_acc: 0.9639 - val_loss: 0.1155 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9825 - loss: 0.0566 - val_acc: 0.9641 - val_loss: 0.1117 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9869 - loss: 0.0427 - val_acc: 0.9662 - val_loss: 0.1116 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9926 - loss: 0.0283 - val_acc: 0.9726 - val_loss: 0.0842 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9934 - loss: 0.0230 - val_acc: 0.9749 - val_loss: 0.0830 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9951 - loss: 0.0201 - val_acc: 0.9736 - val_loss: 0.0824 - learning_rate: 1.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9957 - loss: 0.0182 - val_acc: 0.9737 - val_loss: 0.0832 - learning_rate: 1.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9960 - loss: 0.0173 - val_acc: 0.9743 - val_loss: 0.0826 - learning_rate: 1.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9971 - loss: 0.0156 - val_acc: 0.9746 - val_loss: 0.0817 - learning_rate: 1.0000e-05\n",
      "Epoch 14/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9971 - loss: 0.0148 - val_acc: 0.9742 - val_loss: 0.0817 - learning_rate: 1.0000e-05\n",
      "Epoch 15/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9972 - loss: 0.0148 - val_acc: 0.9746 - val_loss: 0.0820 - learning_rate: 1.0000e-05\n",
      "Epoch 16/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9973 - loss: 0.0147 - val_acc: 0.9746 - val_loss: 0.0819 - learning_rate: 1.0000e-06\n",
      "Epoch 17/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9974 - loss: 0.0142 - val_acc: 0.9743 - val_loss: 0.0819 - learning_rate: 1.0000e-06\n",
      "Epoch 18/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9974 - loss: 0.0136 - val_acc: 0.9742 - val_loss: 0.0819 - learning_rate: 1.0000e-06\n",
      "Epoch 19/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9978 - loss: 0.0134 - val_acc: 0.9742 - val_loss: 0.0819 - learning_rate: 1.0000e-07\n",
      "Epoch 20/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9967 - loss: 0.0151 - val_acc: 0.9742 - val_loss: 0.0819 - learning_rate: 1.0000e-07\n",
      "Epoch 21/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9976 - loss: 0.0137 - val_acc: 0.9742 - val_loss: 0.0819 - learning_rate: 1.0000e-07\n",
      "Epoch 22/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9977 - loss: 0.0130 - val_acc: 0.9742 - val_loss: 0.0819 - learning_rate: 1.0000e-08\n",
      "Epoch 23/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9974 - loss: 0.0135 - val_acc: 0.9742 - val_loss: 0.0819 - learning_rate: 1.0000e-08\n",
      "Epoch 24/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9972 - loss: 0.0141 - val_acc: 0.9742 - val_loss: 0.0819 - learning_rate: 1.0000e-08\n",
      "Epoch 25/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9971 - loss: 0.0150 - val_acc: 0.9742 - val_loss: 0.0819 - learning_rate: 1.0000e-09\n",
      "Epoch 26/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9974 - loss: 0.0137 - val_acc: 0.9742 - val_loss: 0.0819 - learning_rate: 1.0000e-09\n",
      "Epoch 27/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9970 - loss: 0.0147 - val_acc: 0.9742 - val_loss: 0.0819 - learning_rate: 1.0000e-09\n",
      "Epoch 28/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9974 - loss: 0.0142 - val_acc: 0.9742 - val_loss: 0.0819 - learning_rate: 1.0000e-10\n",
      "Epoch 29/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9972 - loss: 0.0144 - val_acc: 0.9742 - val_loss: 0.0819 - learning_rate: 1.0000e-10\n",
      "Epoch 30/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9979 - loss: 0.0127 - val_acc: 0.9742 - val_loss: 0.0819 - learning_rate: 1.0000e-10\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# 모델 컴파일링\n",
    "model = create_model()\n",
    "model.compile(optimizer=Adam(0.001), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "# callback (ReduceLROnPlateau) 선언\n",
    "rlr_cb = ReduceLROnPlateau(\n",
    "    monitor='val_acc',\n",
    "    factor=0.1,\n",
    "    patience=3,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "# 모델 훈련과 동시에 train, validation 데이터에 대한 정확도와 loss 이력 저장\n",
    "history = model.fit(x=train_images, \n",
    "                    y=train_oh_labels, \n",
    "                    batch_size=64, \n",
    "                    epochs=30, \n",
    "                    validation_data=(validation_images, validation_oh_labels), callbacks=[rlr_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecb9f09-c3f3-468c-b9cd-3b709d180432",
   "metadata": {},
   "source": [
    "#### 중간 분석\n",
    "- 모니터링 지표인 val_acc가 epoch 3회 동안 개선되지 않았을 때, 다음 epoch에서 학습률이 1/10으로 줄어드는 것을 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39b63e4-f2de-4685-94a1-e6233c549b49",
   "metadata": {},
   "source": [
    "#### EarlyStopping\n",
    "- patience를 5로 설정함에 따라, epoch 5회 동안 성능이 개선되지 않으면 학습을 조기 종료\n",
    "- 평가 기준은 val_acc의 최대치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea7dc6a9-4d6a-4fac-a363-9b07a120a745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - acc: 0.8205 - loss: 0.6150 - val_acc: 0.9436 - val_loss: 0.1833\n",
      "Epoch 2/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9553 - loss: 0.1507 - val_acc: 0.9542 - val_loss: 0.1416\n",
      "Epoch 3/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9672 - loss: 0.1110 - val_acc: 0.9635 - val_loss: 0.1166\n",
      "Epoch 4/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9763 - loss: 0.0825 - val_acc: 0.9649 - val_loss: 0.1138\n",
      "Epoch 5/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9808 - loss: 0.0661 - val_acc: 0.9693 - val_loss: 0.1002\n",
      "Epoch 6/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9832 - loss: 0.0551 - val_acc: 0.9707 - val_loss: 0.0994\n",
      "Epoch 7/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9866 - loss: 0.0461 - val_acc: 0.9743 - val_loss: 0.0903\n",
      "Epoch 8/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9885 - loss: 0.0376 - val_acc: 0.9713 - val_loss: 0.0960\n",
      "Epoch 9/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9902 - loss: 0.0305 - val_acc: 0.9710 - val_loss: 0.1023\n",
      "Epoch 10/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9922 - loss: 0.0254 - val_acc: 0.9732 - val_loss: 0.1003\n",
      "Epoch 11/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9919 - loss: 0.0258 - val_acc: 0.9647 - val_loss: 0.1262\n",
      "Epoch 12/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9932 - loss: 0.0217 - val_acc: 0.9728 - val_loss: 0.1068\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 모델 컴파일링\n",
    "model = create_model()\n",
    "model.compile(optimizer=Adam(0.001), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "# callback (EarlyStopping) 선언\n",
    "ely_cb = EarlyStopping(\n",
    "    monitor='val_acc',\n",
    "    patience=5,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "# 모델 훈련과 동시에 train, validation 데이터에 대한 정확도와 loss 이력 저장\n",
    "history = model.fit(x=train_images, \n",
    "                    y=train_oh_labels, \n",
    "                    batch_size=64, \n",
    "                    epochs=30, \n",
    "                    validation_data=(validation_images, validation_oh_labels), callbacks=[ely_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f503869b-7348-48b1-a3df-066d0c7e7149",
   "metadata": {},
   "source": [
    "#### 중간 분석\n",
    "- 7번째 epoch에서 val_acc가 최대치를 달성한 이후 5번의 epoch 동안 val_acc의 최대치 갱신이 없었기 때문에  \n",
    "  총 30번의 epoch 중 12번째 epoch에서 학습을 조기 종료함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49c0f0f-b2dd-411b-ab15-3786b2df0497",
   "metadata": {},
   "source": [
    "#### Callback API 종합\n",
    "- 위에서 테스트한 모든 Callback API를 동시에 사용\n",
    "- epoch는 30번으로 설정했으며, 파라미터 값은 그대로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a6c6950-3fd5-4e0a-9d9a-0d697c7b73f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - acc: 0.8277 - loss: 0.6049 - val_acc: 0.9416 - val_loss: 0.1952 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9535 - loss: 0.1600 - val_acc: 0.9545 - val_loss: 0.1461 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9694 - loss: 0.1048 - val_acc: 0.9631 - val_loss: 0.1169 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9763 - loss: 0.0787 - val_acc: 0.9686 - val_loss: 0.1026 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9805 - loss: 0.0647 - val_acc: 0.9718 - val_loss: 0.0949 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9844 - loss: 0.0489 - val_acc: 0.9711 - val_loss: 0.0945 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9873 - loss: 0.0405 - val_acc: 0.9693 - val_loss: 0.1056 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9886 - loss: 0.0362 - val_acc: 0.9712 - val_loss: 0.0986 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9943 - loss: 0.0210 - val_acc: 0.9778 - val_loss: 0.0805 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9969 - loss: 0.0147 - val_acc: 0.9780 - val_loss: 0.0793 - learning_rate: 1.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9975 - loss: 0.0134 - val_acc: 0.9775 - val_loss: 0.0797 - learning_rate: 1.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9977 - loss: 0.0116 - val_acc: 0.9779 - val_loss: 0.0798 - learning_rate: 1.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9980 - loss: 0.0112 - val_acc: 0.9787 - val_loss: 0.0800 - learning_rate: 1.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9985 - loss: 0.0095 - val_acc: 0.9776 - val_loss: 0.0825 - learning_rate: 1.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9985 - loss: 0.0095 - val_acc: 0.9784 - val_loss: 0.0819 - learning_rate: 1.0000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9987 - loss: 0.0089 - val_acc: 0.9785 - val_loss: 0.0826 - learning_rate: 1.0000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9991 - loss: 0.0076 - val_acc: 0.9787 - val_loss: 0.0823 - learning_rate: 1.0000e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9990 - loss: 0.0076 - val_acc: 0.9787 - val_loss: 0.0823 - learning_rate: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# 모델 컴파일링\n",
    "model = create_model()\n",
    "model.compile(optimizer=Adam(0.001), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "# callback (ModelCheckpoint) 선언\n",
    "mcp_cb = ModelCheckpoint(\n",
    "    filepath=\"./callback_files/model.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.model.keras\",\n",
    "    monitor='val_acc',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "# callback (ReduceLROnPlateau) 선언\n",
    "rlr_cb = ReduceLROnPlateau(\n",
    "    monitor='val_acc',\n",
    "    factor=0.1,\n",
    "    patience=3,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "# callback (EarlyStopping) 선언\n",
    "ely_cb = EarlyStopping(\n",
    "    monitor='val_acc',\n",
    "    patience=5,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "# 모델 훈련과 동시에 train, validation 데이터에 대한 정확도와 loss 이력 저장\n",
    "history = model.fit(x=train_images, \n",
    "                    y=train_oh_labels, \n",
    "                    batch_size=64, \n",
    "                    epochs=30, \n",
    "                    validation_data=(validation_images, validation_oh_labels), callbacks=[mcp_cb, rlr_cb, ely_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fe3d4b-2b9a-4668-8693-fc090f519c5d",
   "metadata": {},
   "source": [
    "#### 중간 분석\n",
    "- 13번째 epoch 이후 epoch 5회 동안 val_acc의 최대치 갱신이 없었기 때문에 18번째 epoch에서 학습이 조기 종료됨\n",
    "- 또한 성능이 갱신되었을 때만 파일을 내보냈기 때문에 13번째 epoch의 파일이 가장 고성능의 모델을 가지고 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cd56d95-f446-48e7-8e13-dd213d87acec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - acc: 0.9743 - loss: 0.0828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07249525934457779, 0.978600025177002]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 가장 val_acc를 보인 모델을 불러와서 위 모델과의 검증 결과 비교\n",
    "model = load_model('./callback_files/model.013-0.0800-0.9979.model.keras')\n",
    "model.evaluate(test_images, test_oh_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
