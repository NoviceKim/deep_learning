{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9b6871c-6c82-48e1-8eb3-d929acd9e8ad",
   "metadata": {},
   "source": [
    "### Callback API\n",
    "- 모델이 학습 중에 충돌이 발생하거나 네트워크가 끊기면 모든 훈련 시간이 낭비될 수 있고,  \n",
    "  과적합을 방지하기 위해 훈련을 조기 종료해야 할 수도 있다.\n",
    "- 모델이 학습을 시작하면 학습이 완료될 때까지 어떤 제어도 하지 못하게 되고,  \n",
    "  신경망 훈련을 완료하는 데에는 몇 시간에서 최대 며칠이 걸릴 수도 있기 때문에, 모델을 모니터링 및 제어하는 기능이 필요하다.\n",
    "- 훈련 시(fit()) Callback API를 등록시키면 반복 내에서 특정 이벤트가 발생할 때마다 등록된 callback이 호출되어 수행된다.\n",
    "\n",
    "<br>\n",
    "\n",
    "**ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weight_only=False, mode='auto')**\n",
    "\n",
    "- 특정 조건에 따라 모델 또는 가중치를 파일로 저장한다.\n",
    "- filepath: \"weights.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.weights.hdf5\"와 같이 모델의 체크포인트를 저장한다.\n",
    "- monitor: 모니터링할 성능 지표를 작성한다.\n",
    "- save_best_only: 가장 좋은 성능을 보인 모델을 저장할지에 대한 여부\n",
    "- mode: {auto, min, max} 중 한 가지를 작성한다. monitor의 성능 지표에 따라 적합한 것을 선택한다.  \n",
    "  monitor의 성능 지표가 감소해야 좋은 경우는 min, 증가해야 좋은 경우는 max,  \n",
    "  monitor의 성능 지표명으로부터 자동으로 유추하고 싶다면 auto를 기재한다.\n",
    "\n",
    "<br>\n",
    "\n",
    "**ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', min_lr=0)**\n",
    "\n",
    "- 특정 반복 동안 성능이 개선되지 않을 때, 학습률을 동적으로 감소시킨다.\n",
    "- monitor: 모니터링할 성능 지표를 작성한다.\n",
    "- factor: 학습률을 감소시킬 비율, 새로운 학습률 = 기존 학습률 * factor\n",
    "- patience: 학습률을 줄이기 전 monitor 할 반복 횟수\n",
    "- mode: {auto, min, max} 중 한 가지를 작성한다. monitor의 성능 지표에 따라 적합한 것을 선택한다.  \n",
    "  monitor의 성능 지표가 감소해야 좋은 경우는 min, 증가해야 좋은 경우는 max,  \n",
    "  monitor의 성능 지표명으로부터 자동으로 유추하고 싶다면 auto를 기재한다.\n",
    "\n",
    "<br>\n",
    "\n",
    "**EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='auto')**\n",
    "\n",
    "- 특정 반복동안 성능이 개선되지 않으면 학습을 조기 종료한다.\n",
    "- monitor: 모니터링할 성능 지표를 작성한다.\n",
    "- patience: Early Stopping을 적용하기 전 monitor할 반복 횟수\n",
    "- mode: {auto, min, max} 중 한 가지를 작성한다. monitor의 성능 지표에 따라 적합한 것을 선택한다.  \n",
    "  monitor의 성능 지표가 감소해야 좋은 경우는 min, 증가해야 좋은 경우는 max,  \n",
    "  monitor의 성능 지표명으로부터 자동으로 유추하고 싶다면 auto를 기재한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad33d09d-c472-4d47-bb91-ca2bf09202db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer, Input, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "INPUT_SIZE = 28\n",
    "\n",
    "# 모델 생성 함수 선언\n",
    "def create_model():\n",
    "    input_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE))\n",
    "\n",
    "    x = Flatten()(input_tensor)\n",
    "\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "\n",
    "    output = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dd691fe-5905-49c2-bc5f-277488c87ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# images MinMaxScaling 함수 선언\n",
    "def get_preprocessed_data(images, targets):\n",
    "    images = np.array(images / 255.0, dtype=np.float32)\n",
    "    targets = np.array(targets, dtype=np.float32)\n",
    "\n",
    "    return images, targets\n",
    "\n",
    "# targets 원핫 인코딩 함수 선언 (+ images MinMaxScaling)\n",
    "def get_preprocessed_ohe(images, targets):\n",
    "    images, targets = get_preprocessed_data(images, targets)\n",
    "    oh_targets = to_categorical(targets)\n",
    "\n",
    "    return images, oh_targets\n",
    "\n",
    "# train 데이터에서 validation 데이터 분리하는 함수 선언 (+ images MinMaxScaling, targets 원핫 인코딩)\n",
    "def get_train_valid_test(train_images, train_targets, test_images, test_targets, validation_size=0.2, random_state=124):\n",
    "    train_images, train_oh_targets = get_preprocessed_ohe(train_images, train_targets)\n",
    "    test_images, test_oh_targets = get_preprocessed_ohe(test_images, test_targets)\n",
    "\n",
    "    train_images, validation_images, train_oh_targets, validation_oh_targets = \\\n",
    "    train_test_split(train_images, train_oh_targets, stratify=train_oh_targets, test_size=validation_size, random_state=random_state)\n",
    "\n",
    "    return (train_images, train_oh_targets), (validation_images, validation_oh_targets), (test_images, test_oh_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0032a3c-7de7-4b0a-9c18-96cc8a463863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28) (48000, 10)\n",
      "(12000, 28, 28) (12000, 10)\n",
      "(10000, 28, 28) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "# fashion 데이터 세트 불러오기\n",
    "(train_images, train_targets), (test_images, test_targets) = fashion_mnist.load_data()\n",
    "\n",
    "# 위에서 선언한 함수로 스케일링, 원핫 인코딩, validation 데이터 분리\n",
    "(train_images, train_oh_targets), (validation_images, validation_oh_targets), (test_images, test_oh_targets) = \\\n",
    "                                            get_train_valid_test(train_images, train_targets, test_images, test_targets)\n",
    "\n",
    "# train, validation, test 데이터 shape 출력\n",
    "print(train_images.shape, train_oh_targets.shape)\n",
    "print(validation_images.shape, validation_oh_targets.shape)\n",
    "print(test_images.shape, test_oh_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0faeac14-9128-49ff-a3d5-a5b354d323d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " C 드라이브의 볼륨에는 이름이 없습니다.\n",
      " 볼륨 일련 번호: ED2A-EA84\n",
      "\n",
      " C:\\KDT_0900_KGH\\ai\\deep_learning\\c_tensorflow\\callback_files 디렉터리\n",
      "\n",
      "2024-05-27  오후 01:25    <DIR>          .\n",
      "2024-05-28  오전 10:44    <DIR>          ..\n",
      "               0개 파일                   0 바이트\n",
      "               2개 디렉터리  101,164,036,096 바이트 남음\n"
     ]
    }
   ],
   "source": [
    "# callback_files 경로 표시\n",
    "!dir callback_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887940bf-b5a8-4909-986c-19d8d287e70d",
   "metadata": {},
   "source": [
    "#### ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e65cf5d-4131-4224-950c-9c1c8031e763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - acc: 0.7492 - loss: 0.7346 - val_acc: 0.8373 - val_loss: 0.4578\n",
      "Epoch 2/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8546 - loss: 0.4078 - val_acc: 0.8552 - val_loss: 0.3948\n",
      "Epoch 3/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.8692 - loss: 0.3611 - val_acc: 0.8621 - val_loss: 0.3636\n",
      "Epoch 4/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.8783 - loss: 0.3321 - val_acc: 0.8690 - val_loss: 0.3474\n",
      "Epoch 5/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.8861 - loss: 0.3123 - val_acc: 0.8732 - val_loss: 0.3414\n",
      "Epoch 6/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8878 - loss: 0.3011 - val_acc: 0.8760 - val_loss: 0.3314\n",
      "Epoch 7/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.8946 - loss: 0.2815 - val_acc: 0.8745 - val_loss: 0.3476\n",
      "Epoch 8/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8976 - loss: 0.2676 - val_acc: 0.8818 - val_loss: 0.3144\n",
      "Epoch 9/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9047 - loss: 0.2602 - val_acc: 0.8857 - val_loss: 0.3119\n",
      "Epoch 10/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9083 - loss: 0.2457 - val_acc: 0.8852 - val_loss: 0.3137\n",
      "Epoch 11/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9107 - loss: 0.2385 - val_acc: 0.8834 - val_loss: 0.3240\n",
      "Epoch 12/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9148 - loss: 0.2271 - val_acc: 0.8817 - val_loss: 0.3253\n",
      "Epoch 13/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9162 - loss: 0.2221 - val_acc: 0.8852 - val_loss: 0.3214\n",
      "Epoch 14/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9169 - loss: 0.2214 - val_acc: 0.8883 - val_loss: 0.3076\n",
      "Epoch 15/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9225 - loss: 0.2066 - val_acc: 0.8882 - val_loss: 0.3124\n",
      "Epoch 16/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9255 - loss: 0.2015 - val_acc: 0.8839 - val_loss: 0.3340\n",
      "Epoch 17/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9241 - loss: 0.1986 - val_acc: 0.8891 - val_loss: 0.3366\n",
      "Epoch 18/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9275 - loss: 0.1964 - val_acc: 0.8866 - val_loss: 0.3366\n",
      "Epoch 19/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9286 - loss: 0.1893 - val_acc: 0.8829 - val_loss: 0.3414\n",
      "Epoch 20/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9342 - loss: 0.1774 - val_acc: 0.8907 - val_loss: 0.3276\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# 모델 컴파일링\n",
    "model = create_model()\n",
    "model.compile(optimizer=Adam(0.001), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "# callback (ModelCheckpoint) 선언 - 가중치(weight)만 저장 (확장자 .weights.h5)\n",
    "mcp_cb = ModelCheckpoint(\n",
    "    filepath='./callback_files/weights.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.weights.h5',\n",
    "    monitor='val_loss',\n",
    "\n",
    "    # save_best_only=True: 모든 epoch의 파일을 저장하지 않고, 성능이 좋다고 판단했을 경우에만 저장\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# save_weights_only=False: 가중치가 아닌 모델을 저장 (확장자 .model.keras)\n",
    "# mcp_cb = ModelCheckpoint(\n",
    "#     filepath=\"./callback_files/model.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.model.keras\",\n",
    "#     monitor='val_loss',\n",
    "#     save_best_only=False,\n",
    "#     save_weights_only=False,\n",
    "#     mode='min'\n",
    "# )\n",
    "\n",
    "# 모델 훈련과 동시에 train, validation 데이터에 대한 정확도와 loss 이력 저장\n",
    "history = model.fit(x=train_images, \n",
    "                    y=train_oh_targets, \n",
    "                    batch_size=64, \n",
    "                    epochs=20, \n",
    "                    validation_data=(validation_images, validation_oh_targets), callbacks=[mcp_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9602067f-62ad-4a35-a39c-fa981ca21462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " C 드라이브의 볼륨에는 이름이 없습니다.\n",
      " 볼륨 일련 번호: ED2A-EA84\n",
      "\n",
      " C:\\KDT_0900_KGH\\ai\\deep_learning\\c_tensorflow\\callback_files 디렉터리\n",
      "\n",
      "2024-05-28  오전 10:50    <DIR>          .\n",
      "2024-05-28  오전 10:50    <DIR>          ..\n",
      "2024-05-28  오전 10:50           739,600 weights.001-0.4578-0.8099.weights.h5\n",
      "2024-05-28  오전 10:50           739,600 weights.002-0.3948-0.8577.weights.h5\n",
      "2024-05-28  오전 10:50           739,600 weights.003-0.3636-0.8719.weights.h5\n",
      "2024-05-28  오전 10:50           739,600 weights.004-0.3474-0.8788.weights.h5\n",
      "2024-05-28  오전 10:50           739,600 weights.005-0.3414-0.8856.weights.h5\n",
      "2024-05-28  오전 10:50           739,600 weights.006-0.3314-0.8888.weights.h5\n",
      "2024-05-28  오전 10:50           739,600 weights.007-0.3476-0.8945.weights.h5\n",
      "2024-05-28  오전 10:50           739,600 weights.008-0.3144-0.8983.weights.h5\n",
      "2024-05-28  오전 10:50           739,600 weights.009-0.3119-0.9025.weights.h5\n",
      "2024-05-28  오전 10:50           739,600 weights.010-0.3137-0.9065.weights.h5\n",
      "2024-05-28  오전 10:50           739,600 weights.011-0.3240-0.9092.weights.h5\n",
      "2024-05-28  오전 10:50           739,600 weights.012-0.3253-0.9125.weights.h5\n",
      "2024-05-28  오전 10:50           739,600 weights.013-0.3214-0.9142.weights.h5\n",
      "2024-05-28  오전 10:50           739,600 weights.014-0.3076-0.9164.weights.h5\n",
      "2024-05-28  오전 10:50           739,600 weights.015-0.3124-0.9193.weights.h5\n",
      "2024-05-28  오전 10:50           739,600 weights.016-0.3340-0.9239.weights.h5\n",
      "2024-05-28  오전 10:50           739,600 weights.017-0.3366-0.9228.weights.h5\n",
      "2024-05-28  오전 10:50           739,600 weights.018-0.3366-0.9276.weights.h5\n",
      "2024-05-28  오전 10:50           739,600 weights.019-0.3414-0.9293.weights.h5\n",
      "2024-05-28  오전 10:50           739,600 weights.020-0.3276-0.9311.weights.h5\n",
      "              20개 파일          14,792,000 바이트\n",
      "               2개 디렉터리  101,149,134,848 바이트 남음\n"
     ]
    }
   ],
   "source": [
    "# callback_files 경로 표시\n",
    "!dir callback_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e682e22-2d06-4bba-8057-49f05c404a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - acc: 0.8857 - loss: 0.3469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34664174914360046, 0.885699987411499]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 현재 모델 성능 검증\n",
    "model.evaluate(test_images, test_oh_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8a81b06-ff74-4c02-a011-6fa3a358120c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 959us/step - acc: 0.8857 - loss: 0.3469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34664174914360046, 0.885699987411499]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로운 모델 생성 후 미리 설정한 가중치 부여\n",
    "model = create_model()\n",
    "model.load_weights('./callback_files/weights.020-0.3276-0.9311.weights.h5')\n",
    "\n",
    "# 가중치 설정한 모델로 성능 검증 - 같은 모델에 가중치도 같으니 결과 역시 같다\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "model.evaluate(test_images, test_oh_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b8e580-0d54-40f2-ad80-b2b8cc031a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 자체를 내보냈을 경우, 아래처럼 모델 파일 불러온 다음 바로 사용하면 된다\n",
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "# model = load_model('./callback_files/model.020-0.3350-0.9287.model.keras')\n",
    "# model.evaluate(test_images, test_oh_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a643283d-cc12-43f5-9fa1-7a4e6cf66c06",
   "metadata": {},
   "source": [
    "#### ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc1aa395-4028-4e0a-b2dd-b92b4c1ac12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - acc: 0.7408 - loss: 0.7531 - val_acc: 0.8527 - val_loss: 0.4087 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8583 - loss: 0.3960 - val_acc: 0.8502 - val_loss: 0.4005 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8711 - loss: 0.3604 - val_acc: 0.8644 - val_loss: 0.3624 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.8776 - loss: 0.3301 - val_acc: 0.8734 - val_loss: 0.3537 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.8876 - loss: 0.3097 - val_acc: 0.8673 - val_loss: 0.3567 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.8900 - loss: 0.2969 - val_acc: 0.8771 - val_loss: 0.3310 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.8955 - loss: 0.2814 - val_acc: 0.8814 - val_loss: 0.3228 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.8991 - loss: 0.2704 - val_acc: 0.8753 - val_loss: 0.3407 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9016 - loss: 0.2633 - val_acc: 0.8859 - val_loss: 0.3234 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9170 - loss: 0.2245 - val_acc: 0.8911 - val_loss: 0.3016 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9187 - loss: 0.2195 - val_acc: 0.8910 - val_loss: 0.2998 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9211 - loss: 0.2134 - val_acc: 0.8918 - val_loss: 0.3010 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9248 - loss: 0.2073 - val_acc: 0.8926 - val_loss: 0.3027 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9231 - loss: 0.2039 - val_acc: 0.8942 - val_loss: 0.2988 - learning_rate: 1.0000e-05\n",
      "Epoch 15/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9249 - loss: 0.2041 - val_acc: 0.8932 - val_loss: 0.2987 - learning_rate: 1.0000e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9262 - loss: 0.2030 - val_acc: 0.8938 - val_loss: 0.2985 - learning_rate: 1.0000e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9263 - loss: 0.2010 - val_acc: 0.8929 - val_loss: 0.2984 - learning_rate: 1.0000e-05\n",
      "Epoch 18/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9243 - loss: 0.2026 - val_acc: 0.8931 - val_loss: 0.2986 - learning_rate: 1.0000e-05\n",
      "Epoch 19/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9276 - loss: 0.1972 - val_acc: 0.8929 - val_loss: 0.2985 - learning_rate: 1.0000e-05\n",
      "Epoch 20/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9251 - loss: 0.2015 - val_acc: 0.8932 - val_loss: 0.2985 - learning_rate: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# 모델 컴파일링\n",
    "model = create_model()\n",
    "model.compile(optimizer=Adam(0.001), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "# callback (ReduceLROnPlateau) 선언\n",
    "rlr_cb = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# 모델 훈련과 동시에 train, validation 데이터에 대한 정확도와 loss 이력 저장\n",
    "history = model.fit(x=train_images, \n",
    "                    y=train_oh_targets, \n",
    "                    batch_size=64, \n",
    "                    epochs=20, \n",
    "                    validation_data=(validation_images, validation_oh_targets), callbacks=[rlr_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fb1873-ff6a-41c7-97c6-a0ff168ae42a",
   "metadata": {},
   "source": [
    "#### EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3c207ae-1375-4793-92cc-1446adeb455d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - acc: 0.7299 - loss: 0.7767 - val_acc: 0.8461 - val_loss: 0.4236\n",
      "Epoch 2/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8518 - loss: 0.4123 - val_acc: 0.8565 - val_loss: 0.3979\n",
      "Epoch 3/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.8665 - loss: 0.3713 - val_acc: 0.8645 - val_loss: 0.3662\n",
      "Epoch 4/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.8756 - loss: 0.3377 - val_acc: 0.8753 - val_loss: 0.3492\n",
      "Epoch 5/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.8851 - loss: 0.3127 - val_acc: 0.8648 - val_loss: 0.3655\n",
      "Epoch 6/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.8897 - loss: 0.2963 - val_acc: 0.8772 - val_loss: 0.3384\n",
      "Epoch 7/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8923 - loss: 0.2879 - val_acc: 0.8789 - val_loss: 0.3240\n",
      "Epoch 8/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.8986 - loss: 0.2761 - val_acc: 0.8808 - val_loss: 0.3183\n",
      "Epoch 9/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9030 - loss: 0.2623 - val_acc: 0.8800 - val_loss: 0.3222\n",
      "Epoch 10/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9035 - loss: 0.2577 - val_acc: 0.8857 - val_loss: 0.3164\n",
      "Epoch 11/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9089 - loss: 0.2463 - val_acc: 0.8701 - val_loss: 0.3654\n",
      "Epoch 12/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9103 - loss: 0.2399 - val_acc: 0.8814 - val_loss: 0.3313\n",
      "Epoch 13/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9136 - loss: 0.2338 - val_acc: 0.8847 - val_loss: 0.3328\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 모델 컴파일링\n",
    "model = create_model()\n",
    "model.compile(optimizer=Adam(0.001), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "# callback (EarlyStopping) 선언\n",
    "ely_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# 모델 훈련과 동시에 train, validation 데이터에 대한 정확도와 loss 이력 저장\n",
    "history = model.fit(x=train_images, \n",
    "                    y=train_oh_targets, \n",
    "                    batch_size=64, \n",
    "                    epochs=20, \n",
    "                    validation_data=(validation_images, validation_oh_targets), callbacks=[ely_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "610bb433-8925-4e1e-af38-3bb738ba5afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - acc: 0.7323 - loss: 0.7640 - val_acc: 0.8508 - val_loss: 0.4114 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8552 - loss: 0.4021 - val_acc: 0.8583 - val_loss: 0.3867 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.8711 - loss: 0.3562 - val_acc: 0.8640 - val_loss: 0.3673 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8817 - loss: 0.3250 - val_acc: 0.8717 - val_loss: 0.3414 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8871 - loss: 0.3084 - val_acc: 0.8695 - val_loss: 0.3482 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8928 - loss: 0.2920 - val_acc: 0.8748 - val_loss: 0.3381 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.8953 - loss: 0.2815 - val_acc: 0.8774 - val_loss: 0.3306 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.8993 - loss: 0.2722 - val_acc: 0.8808 - val_loss: 0.3247 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9025 - loss: 0.2630 - val_acc: 0.8763 - val_loss: 0.3361 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9029 - loss: 0.2611 - val_acc: 0.8847 - val_loss: 0.3198 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9097 - loss: 0.2431 - val_acc: 0.8815 - val_loss: 0.3215 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9089 - loss: 0.2407 - val_acc: 0.8873 - val_loss: 0.3176 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9121 - loss: 0.2327 - val_acc: 0.8849 - val_loss: 0.3215 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9141 - loss: 0.2266 - val_acc: 0.8875 - val_loss: 0.3172 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9159 - loss: 0.2229 - val_acc: 0.8714 - val_loss: 0.3547 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9207 - loss: 0.2124 - val_acc: 0.8804 - val_loss: 0.3335 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9326 - loss: 0.1812 - val_acc: 0.8957 - val_loss: 0.3062 - learning_rate: 1.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9354 - loss: 0.1718 - val_acc: 0.8954 - val_loss: 0.3038 - learning_rate: 1.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9374 - loss: 0.1663 - val_acc: 0.8967 - val_loss: 0.3074 - learning_rate: 1.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9390 - loss: 0.1644 - val_acc: 0.8953 - val_loss: 0.3075 - learning_rate: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# 모델 컴파일링\n",
    "model = create_model()\n",
    "model.compile(optimizer=Adam(0.001), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "# callback (ModelCheckpoint) 선언 - 가중치(weight)만 저장\n",
    "mcp_cb = ModelCheckpoint(\n",
    "    filepath='./callback_files/weights.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.weights.h5',\n",
    "    monitor='val_loss',\n",
    "\n",
    "    # save_best_only=True: 모든 epoch의 파일을 저장하지 않고, 성능이 좋다고 판단했을 경우에만 저장\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# callback (ReduceLROnPlateau) 선언\n",
    "rlr_cb = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# callback (EarlyStopping) 선언\n",
    "ely_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# 모델 훈련과 동시에 train, validation 데이터에 대한 정확도와 loss 이력 저장\n",
    "history = model.fit(x=train_images, \n",
    "                    y=train_oh_targets, \n",
    "                    batch_size=64, \n",
    "                    epochs=20, \n",
    "                    validation_data=(validation_images, validation_oh_targets), callbacks=[mcp_cb, rlr_cb, ely_cb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
